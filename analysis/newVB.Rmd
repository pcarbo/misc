---
title: "New attempt at VB"
author: "Matthew Stephens"
date: 2017-10-27
output: html_document
---

<!-- The file analysis/chunks.R contains chunks that define default settings
shared across the workflowr files. -->
```{r read-chunk, include=FALSE, cache=FALSE}
knitr::read_chunk("chunks.R")
```

<!-- Update knitr chunk options -->
```{r knitr-opts-chunk, include=FALSE}
```

<!-- Insert the date the file was last updated -->
```{r last-updated, echo=FALSE, results='asis'}
```

<!-- Insert the code version (Git commit SHA1) if Git repository exists and R
 package git2r is installed -->
```{r code-version, echo=FALSE, results='asis'}
```

# Outline

The model is:
$$Y_i = \sum_{l=1}^L \sum_j X_{ij} \gamma_{lj} \beta_{lj} + e_i$$

$$(\gamma_{l1},\dots,\gamma_{lp}) \sim Multinomial(1,\pi)$$
$$\beta_{lj} \sim g()$$.

For now assume $g$ is $N(0,\sigma_\beta^2)$, and $\pi = (1/p,\dots,1/p)$.

The idea is that there are $L$ non-zero effects. (though see later comment.)
For each of $l=1,\dots,L$ we assume that exactly 1 of the $p$ variables has an effect, as indicated by $\gamma_{lj}$. $\pi$ is a $p$ vector of prior probabilities summing to 1. 

$g()$ is an effect distribution for the non-zero effects.
$g()$ could be a mixture of normals as in my ash work. $g$ could include a point mass at 0, in which case $L$ is an upper bound on the number of non-zero effects, rather than an actual number of effects.
But I'm not sure we need to go this far... for now we assume $g$ normal.


The idea is to seek a variational approximation (or expectation propogation?) based on 
$$q(\gamma,\beta) = \prod_l q(\gamma_l, \beta_l)$$


Possibly we would further factorize this to 
$q(\gamma_l,\beta_l) = q(\gamma_l) q(\beta_l)$, although it might be $q(\gamma_l) q(\beta_l | \gamma_l)$, I'm not sure.

However, cruicially, we do not factorize the $q(\gamma_l)$ 
across the $p$ elements of $\gamma_l$: 
$\gamma_l$ is a binary vector with exactly one non-zero element, so $q(\gamma_l) = Multinimial(1, \alpha_l)$ say where $\alpha_l=(\alpha_{l1,\dots,\alpha_lp})$ are variational parameters.

Here I have simply guessed at what the form of the variational
updates might look like, by mimicking the updates from Carbonetto and Stephens. I borrowed and modified 
code from the function `varbvsnormupdate` from `varbvs`. 
Notice that we update all the variables simultaneously for each $l$... not one at a time. (This is a computational advantage of this approach, at least when coded in R.!)

In brief, the variational parameters are as in Carbonetto and Stephens,
but they become $L \times p$ matrices.
That is they are $\alpha,\mu,s$ 
where $\alpha_{lj}$ is the posterior mean for $\gamma_{lj}$,
$\mu_{lj}$ is the posterior mean on $\beta_{lj}$, and $s_{lj}$ is the posterior variance.

In the code below `alpha[l,] mu[l,]` is an estimate of
$\hat{\beta}[l,]$, and a sum of this over $l$ is an estimate
of the overall SNP effects. Call this sum `r` as in Carbonetto
and Stephens. The variable `Xr` is `t(X) %*% r`, effectively the 
"fitted values".


Lots to do: 
- derive these updates (or correct them!) and the VB lower bound.
- investigate how it compares with exact calculations in small problems
- think about how to deal with automatically choosing L or estimating g
- hyperparameter estimation...

```{r}
knitr::read_chunk("newVB.funcs.R")
```

```{r newVB.funcs}
```

# Null simulation

This is a null simulation. Actually I don't understand
why it converges to this result where all the posteriors are the same for each $l$. Might be interesting to understand.
```{r}
set.seed(1)
n = 1000
p = 1000
y = rnorm(n)
X = matrix(rnorm(n*p),nrow=n,ncol=p)
res =fit(X,y,niter=100,calc_elbo=TRUE)
n_in_CI(res)
lfsr_fromfit(res)
pplot(X,y,res,main="null simulation")
```

Note that the ELBO is increasing
```{r}
plot(res$elbo)
```


#Simple Simulation

Here the first 4 variables are actually real... just a sanity check!
```{r}
n = 1000
p = 1000
beta = rep(0,p)
beta[1] = 1
beta[2] = 1
beta[3] = 1
beta[4] = 1
X = matrix(rnorm(n*p),nrow=n,ncol=p)
y = X %*% beta + rnorm(n)
res =fit(X,y,niter=100,calc_elbo=TRUE)
n_in_CI(res)
lfsr_fromfit(res)
pplot(X,y,res,main="simple simulation")
plot(res$elbo,main="ELBO is increasing")
```


# Simulate with LD blocks

We will simulate data with some "LD structure". b=3 blocks of p=10 variables,
each correlated through some latent Z.
The phenotype model is $Y = X_1+...+X_b + e$ where
$X_1,\dots,X_b$ are each a member of a block, and $e$ is $N(0,sd)$.

```{r}
set.seed(1)
simulate = function(n=100,p=10,b=3,sd=1){
  Z = list()
  X = list()
  Y = list()
  for(i in 1:b) Z[[i]] = rnorm(n)
  for(i in 1:b) X[[i]] = Z[[i]] + matrix(rnorm(n*p),nrow=n)
  for(i in 1:b) Y[[i]] = X[[i]][,1] 
  
  X = do.call(cbind,X) # bind columns of X and Y
  Y = do.call(cbind,Y)
  Y = rowSums(Y) # each of the betas is 1
  
  Y = Y + rnorm(n,sd = sd)
  return(list(X=X,Y=Y))
}
d = simulate()
```

Now fit the model:
```{r}
res.LD =fit(d$X,d$Y,niter=100)
n_in_CI(res.LD)
lfsr_fromfit(res.LD)
pplot(d$X,d$Y,res.LD,main="LD simulation",CImax=10)
```

# Real data

These are GTEX data from Thyroid.
```{r}
d=readRDS("../data/Thyroid.FMO2.pm1Mb.RDS")
storage.mode(d$X) <- "double"
d$X <- d$X[,3501:4500]
pos <- d$pos[3501:4500]
X = d$X
y = d$y
Z = d$Z
Xresid= X
p =ncol(Xresid)
for(i in 1:p){Xresid[,i] = lm(X[,i]~Z)$resid}
yresid = lm(y~Z)$resid
res.gtex =fit(Xresid,yresid,niter=100,calc_elbo=TRUE)
n_in_CI(res.gtex)
lfsr_fromfit(res.gtex)
pplot(Xresid,yresid,res.gtex)
plot(res.gtex$elbo,main="ELBO is increasing")
```

Interestingly, the variable with smallest $p$ value is not in the CIs of the most confident eQTLs. It seems that when we control for the other hits, that
variable is no longer that significant.

Notice that only $l=2,\dots,5$ have small lfsr. So the first one can probably be ignored. 
Of the others, there are 3 eQTLs that are fairly well mapped (95% CI contains 5-19 SNPs) and one that is not all well mapped (152).

Here we pick out the top marker for each $L$ and look at the BFs.
Also compare with the top markers found by `varbvs`.
We see the BF for the top 4 markers is higher than those from varbvs,
which is encouraging.
```{r}
#find top hits
tophits = apply(res.gtex$alpha,1,which.max)
markers = colnames(Xresid)[tophits]

# varbvs, top 4 SNPs:
markers.varbvs<- c("chr1_171168633_C_A_b38",
              "chr1_171147265_C_A_b38",
              "chr1_171164750_C_A_b38",
              "chr1_171178589_C_T_b38")
#simple bf calculation X an n by p matrix of genoytpes
log10BF = function(X,y,sigmaa){
p = ncol(X)
n = nrow(X)
X = cbind(rep(1,n),X)
invnu = diag(c(0,rep(1/sigmaa^2,p)))
invOmega = invnu + t(X) %*% X
B = solve(invOmega, t(X) %*% cbind(y))
invOmega0 = n
return(-0.5*log10(det(invOmega)) + 0.5*log10(invOmega0) - p*log10(sigmaa) -(n/2) * (log10( t(y- X %*% B) %*% y) - log10(t(y) %*% y - n*mean(y)^2) ))  
}

c(log10BF(Xresid[,markers], yresid,0.5),
log10BF(Xresid[,markers[2:5]], yresid,0.5),
log10BF(Xresid[,markers[2:4]], yresid,0.5),
log10BF(Xresid[,markers.varbvs], yresid,0.5))

```


## Simulations based on real data

Here we take the real genotypes (actually the residuals after removing Z) from the data above, and simulate effects with the effect sizes
matched to the 4 significant top SNPs identified above. 

```{r}
set.seed(1)
p =ncol(Xresid)
n = nrow(Xresid)
b = rep(0,p)
index = apply(res.gtex$alpha,1,which.max)[-1]
b[index] = diag(res.gtex$mu[2:5,index])
fitted = Xresid %*% b
sigma = sqrt(var(yresid) - var(fitted))
ysim = fitted + rnorm(n, 0, sigma)

write_finemap_files = function(X,Y,dir,prefix){
  dir = normalizePath(dir)
  z = calc_z(X,Y)
  n = length(Y)
  write.table(z,file.path(dir,paste0(prefix,".z")),quote=F,col.names=F)
  write.table(cor(Xresid),file.path(dir,paste0(prefix,".ld")),quote=F,col.names=F,row.names=FALSE)
  write.table(t(c(0,0,0,1)),file.path(dir,paste0(prefix,".k")),quote=F,col.names=F,row.names=FALSE)
  write("z;ld;snp;config;k;log;n-ind",file=file.path(dir,"data"))
  write(paste(file.path(dir,paste0(prefix,".z")),
              file.path(dir,paste0(prefix,".ld")),
              file.path(dir,paste0(prefix,".snp")),
              file.path(dir,paste0(prefix,".config")),
              file.path(dir,paste0(prefix,".k")),
              file.path(dir,paste0(prefix,".log")),
              n,sep=";"),
        file=file.path(dir,"data"),append=TRUE)
}

write_finemap_files(Xresid,ysim,"../data/finemap_data/fmo2.sim","fmo2.sim")

# this version puts all weight on k=4 
# and gives results more similar to the VB approach
system("~/finemap_v1.1_MacOSX/finemap --sss --in-files ../data/finemap_data/fmo2.sim/data --prior-k --n-iterations 1000000 --prior-std 0.4 --regions 1")
system("mv ../data/finemap_data/fmo2.sim/fmo2.sim.snp ../data/finemap_data/fmo2.sim/fmo2.sim.k4.snp")
system("mv ../data/finemap_data/fmo2.sim/fmo2.sim.config ../data/finemap_data/fmo2.sim/fmo2.sim.k4.config")

# this version uses default prior
system("~/finemap_v1.1_MacOSX/finemap --sss --in-files ../data/finemap_data/fmo2.sim/data --n-iterations 1000000 --prior-std 0.4 --regions 1")


#system("~/finemap_v1.1_MacOSX/finemap --sss --in-files ../data/finemap_data/fmo2.sim/data --n-iterations 1000000 --prior-std 0.4 --regions 1 --prob-tol 0.00001")

# Wrote these files to send to William for DAP
write.table(Xresid,"../data/finemap_data/fmo2.sim/Xresid.txt",quote=F,col.names=F,row.names=FALSE)
write.table(ysim,"../data/finemap_data/fmo2.sim/ysim.txt",quote=F,col.names=F,row.names=FALSE)

z = calc_z(Xresid,ysim)
write.table(c("Zscore",z),"../data/paintor_data/fmo2.sim/fmo2.sim.z",quote=F,col.names=F,row.names=FALSE)
write.table(cor(Xresid),"../data/paintor_data/fmo2.sim/fmo2.sim.ld",quote=F,col.names=F,row.names=FALSE)
write.table(cor(Xresid[,1:99]),"../data/paintor_data/fmo2.sim/fmo2.sim.short.ld",quote=F,col.names=F,row.names=FALSE)
write.table(rep(1,length(z)),"../data/paintor_data/fmo2.sim/fmo2.sim.annotations",quote=F,col.names=F,row.names=FALSE)

res.sim = fit(Xresid,ysim,niter=100)
n_in_CI(res.sim)
lfsr_fromfit(res.sim)

#try with sigma="true" sigma
# res2.sim = fit(Xresid,ysim,sa=0.5,sigma=sigma^2,niter=100)
# n_in_CI(res2.sim)
# lfsr_fromfit(res2.sim)
```

Compare with p values
```{r}
pplot(Xresid,ysim,res.sim,pos,b,100)
ci = list()
for(i in 1:5){ci[[i]] = which(in_CI_x(res.sim$alpha[i,])>0)}

pip.sim = colSums(res.sim$alpha)
plot(pip.sim)
which(b!=0)
points(which(b!=0),pip.sim[which(b!=0)],col=2,pch=16)
```

# Compare with FINEMAP 

The new VB method gives similar results to FINEMAP (with FINEMAP set to $k=4$)

```{r}
res.fm = read.table("../data/finemap_data/fmo2.sim/fmo2.sim.snp",header=TRUE,sep=" ")
pip.fm = rep(0,1000)
pip.fm[res.fm$index] = res.fm$snp_prob


res.fm.k4 = read.table("../data/finemap_data/fmo2.sim/fmo2.sim.k4.snp",header=TRUE,sep=" ")
pip.fm.k4 = rep(0,1000)
pip.fm.k4[res.fm.k4$index] = res.fm.k4$snp_prob



plot(pip.sim,pip.fm.k4,xlab="PIP (new VB method)",ylab="PIP (FINEMAP, k=4)", main="New VB vs FINEMAP with k=4")
points(pip.sim[which(b!=0)],pip.fm.k4[which(b!=0)],col=2,pch=16)
abline(a=0,b=1)


```

Now compare with DAP. William sent me two different DAP results,
the first with default settings, and the second with the residual variance set to be equal to var(y), which is in some sense "conservatve". It turns
out the latter agrees really well with FINEMAP with default prior.
```{r}
res.dap = read.table("../data/finemap_data/fmo2.sim/dap_out_snp.txt",stringsAsFactors = FALSE)
res.dap$snp = as.numeric(substr(res.dap$V2,4,6))
pip.dap = rep(0,1000)
pip.dap[res.dap$snp] = res.dap$V3

res.dap2 = read.table("../data/finemap_data/fmo2.sim/dap_out2_snp.txt",stringsAsFactors = FALSE)
res.dap2$snp = as.numeric(substr(res.dap2$V2,4,6))
pip.dap2 = rep(0,1000)
pip.dap2[res.dap2$snp] = res.dap2$V3

plot(pip.dap2,pip.fm,main ="DAP (conservative) vs FINEMAP (defaults)",xlab="DAP",ylab="FINEMAP")
points(pip.dap2[which(b!=0)],pip.fm[which(b!=0)],col=2,pch=16)
abline(a=0,b=1)


plot(pip.dap2,pip.dap,main ="DAP (conservative) vs DAP (defaults)",xlab="DAP (conservative)",ylab="DAP (default)")
points(pip.dap2[which(b!=0)],pip.dap[which(b!=0)],col=2,pch=16)
abline(a=0,b=1)
```

In contrast, Paintor results seem pretty different:
```{r}
pip.p = read.table("~/PAINTOR_V3.0/myData/fmo2.sim.results",header=TRUE)[,2]
plot(pip.p,pip.sim)
points(pip.p[which(b!=0)],pip.sim[which(b!=0)],col=2,pch=16)
abline(a=0,b=1)
```


Compare log10BF. Note the top log10BF from finemap was
36.7 (for a 4 marker model). So similar, but not identical. (I haven't been careful about 
making sure parameters are exactly same across methods.)
```{r}
tophits = apply(res.sim$alpha,1,which.max)
markers = colnames(Xresid)[tophits]
log10BF(Xresid[,markers[1:3]],ysim,0.4)
log10BF(Xresid[,markers[1:4]],ysim,0.4)
```


# Run on ACTN3 data

```{r}
d=readRDS("../data/Muscle_Skeletal.ACTN3.pm1Mb.RDS")
storage.mode(d$X) <- "double"
#d$X <- d$X[,3501:4500]
    
X = d$X
y = d$y
Z = d$Z
Xresid= X
p =ncol(Xresid)
for(i in 1:p){Xresid[,i] = lm(X[,i]~Z)$resid}
yresid = lm(y~Z)$resid
res.actn3 =fit(Xresid,yresid,niter=100)
n_in_CI(res.actn3)
lfsr_fromfit(res.actn3)
pplot(Xresid,yresid,res.actn3)
```


## Session information

<!-- Insert the session information into the document -->
```{r session-info}
```
